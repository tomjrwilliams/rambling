---
title: "PCA: Rates"
author: "Tom Williams"
date: "2023-08-08"
categories: []
draft: false
execute:
  daemon: false
---

In this post, ...

## Setup

```{python}
#| echo: false
#| code-fold: true
#| code-summary: "Auto reload"
%load_ext autoreload
%autoreload 2
```

```{python}
#| echo: false
#| code-fold: true
#| code-summary: "Environment"
import os
import sys
import importlib
sys.path.append("C:/hc/rambling")
sys.path.append("C:/hc/xtuples/src")
sys.path.append("C:/hc/xfactors/src")
os.chdir("c:/hc/xfactors")
```

```{python}
#| code-fold: false
#| code-summary: "Imports"
import numpy
import pandas
import jax
import jax.numpy

import xtuples as xt
import xfactors as xf
```

### Data

```{python}
#| code-fold: false
#| code-summary: "Returns"
dfs_curves = xf.bt.data.curve_dfs(
    curves=xt.iTuple([
        "YCSW0023",
        "YCGT0025",
        "YCSW0045",
        "YCGT0016",
    ]).extend(
        xf.bt.data.curves.CORP_USD
    ).extend(
        xf.bt.data.curves.CORP_EUR
    ),
    dp="../xfactors/__local__/csvs"
)
dfs_curves = {
    curve: xf.utils.dfs.apply_na_threshold(
        df, na_threshold=(0., 0.,), na_padding=(0.2, 0.4,)
    )
    for curve, df in dfs_curves.items()
}
```


```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def curve_chart(d_start, d_end, curve):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)
    df = xf.bt.data.enumerate_strip_curve(df, curve, reverse=True)
    return xf.visuals.graphs.df_line_chart(
        xf.utils.dfs.melt_with_index(df, index_as="date", variable_as="tenor"),
        x="date",
        y="value",
        color="tenor",
        discrete_color_scale="Blues",
    )
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def tenor_chart(d_start, d_end, tenor, curves):
    df = xf.bt.data.curves_by_tenor({
        curve: df for curve, df in dfs_curves.items() if curve in curves
    }, tenor = tenor)
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)
    df = xf.bt.data.enumerate_strip_tenor(df, tenor, reverse=True)
    return xf.visuals.graphs.df_line_chart(
        xf.utils.dfs.melt_with_index(df, index_as="date", variable_as="curve"),
        x="date",
        y="value",
        color="curve",
        discrete_color_scale="Blues",
    )
```



```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
import functools
@functools.lru_cache(maxsize=10)
def fit_pca_kernel(curve, d_start, d_end, n = 3):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)

    data = (df,)
    
    N_STAGES = 5
    model, STAGES = xf.Model().init_stages(N_STAGES)
    INPUTS, SETUP, PARAMS, ENCODE, DECODE, STRUCTURE = STAGES

    model, stages = xf.Model().init_stages(N_STAGES)
    assert stages.len() == STAGES.len()

    n = n_factors

    model = (
        .add_input(xf.nodes.inputs.dfs.Input_DataFrame_Wide(
            allow_missing_columns=True,
            allow_missing_indices=False,
            allow_new_columns=True,
            allow_new_indices=False,
            na_threshold_columns=0.,
            na_threshold_indices=0.,
        ))
        .add_node(SETUP, xf.nodes.cov.vanilla.Cov(
            data=xf.Loc.result(INPUTS, 0),
        ), static = True)
        
        # TODO: map columns to embeddings

        # TODO: kernel on embeddings (-> cov)

        # TODO: likelihood (?) decomp on the cov to get weight matrix

        # TODO: mse on round-trip encode-decode given weights

        # possibly other shape constraints on weights / factors

        .add_constraint(xf.nodes.constraints.loss.Constraint_VMSE(
            l=xf.Loc.result(INPUTS, 0),
            r=xf.Loc.result(DECODE, 0),
        ))
    )

    # todo, try adding a further shape constraint that pc0 is positive

    model = define_model(n_factors, n_noise).init(data).optimise(
        data,
        iters = 2500,
        rand_init=10, 
        max_error_unchanged=0.5,
    )
    results = model.apply(data)

    params = model.params
    weights = params[PARAMS][0]
    weights_agg = results[STRUCTURE][0][0]
    latents = params[PARAMS][1]
    loadings = params[PARAMS][2]

    return model, weights, weights_agg, latents, loadings
```


Can you back out an implied covariance contribution (tenor level)

Per factor

beta = cov / var

ratio of betas?

-> cov = beta * var?


What, and then take PC1 from each covariance contribution separately

Rather than a sum decomposition over all of them?



Where we can then extend to rolling, so we have separate pivot points (per factor)

And a steepness of the kernel (rolling over time)


```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
curve_chart(xf.utils.dates.y(2005), xf.utils.dates.y(2023), "USD-G")
```


```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
curve_chart(xf.utils.dates.y(2005), xf.utils.dates.y(2023), "USD-S")
```

