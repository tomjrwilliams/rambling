---
title: "Rates: Tenor Kernel"
author: "Tom Williams"
date: "2023-08-08"
categories: []
draft: false
execute:
  daemon: false
---

In this post, we demonstrate how to design a yield curve covariance kernel function over tenor space.

We then show how to use such a kernel to derive yield curve factor loadings for previously unseen tenors.

Finally, we conclude with a review of how our kernel parameters vary with time, and implications w.r.t further work.

## Setup

```{python}
#| echo: false
#| code-fold: true
#| code-summary: "Auto reload"
%load_ext autoreload
%autoreload 2
```

```{python}
#| echo: false
#| code-fold: true
#| code-summary: "Environment"
import os
import sys
import importlib
sys.path.append("C:/hc/rambling")
sys.path.append("C:/hc/xtuples/src")
sys.path.append("C:/hc/xfactors/src")
os.chdir("c:/hc/xfactors")
```

```{python}
#| code-fold: false
#| code-summary: "Imports"
import numpy
import pandas
import jax
import jax.numpy

import xtuples as xt
import xfactors as xf
```

### Data

```{python}
#| code-fold: false
#| code-summary: "Returns"
dfs_curves = xf.bt.data.curve_dfs(
    curves=xt.iTuple([
        "YCSW0023",
        "YCGT0025",
        "YCSW0045",
        "YCGT0016",
    ]),
    # .extend(
    #     xf.bt.data.curves.CORP_USD
    # ).extend(
    #     xf.bt.data.curves.CORP_EUR
    # ),
    dp="../xfactors/__local__/csvs"
)
dfs_curves = {
    curve: xf.utils.dfs.apply_na_threshold(
        df, na_threshold=(0., 0.,), na_padding=(0.2, 0.4,)
    )
    for curve, df in dfs_curves.items()
}
```


```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def curve_chart(d_start, d_end, curve):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)
    df = xf.bt.data.enumerate_strip_curve(df, curve, reverse=True)
    return xf.visuals.graphs.df_line_chart(
        xf.utils.dfs.melt_with_index(df, index_as="date", variable_as="tenor"),
        x="date",
        y="value",
        color="tenor",
        discrete_color_scale="Blues",
    )
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def tenor_chart(d_start, d_end, tenor, curves):
    df = xf.bt.data.curves_by_tenor({
        curve: df for curve, df in dfs_curves.items() if curve in curves
    }, tenor = tenor)
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)
    df = xf.bt.data.enumerate_strip_tenor(df, tenor, reverse=True)
    return xf.visuals.graphs.df_line_chart(
        xf.utils.dfs.melt_with_index(df, index_as="date", variable_as="curve"),
        x="date",
        y="value",
        color="curve",
        discrete_color_scale="Blues",
    )
```



```{python}
#| code-fold: false
#| code-summary: "PCA Factor Corr"
def curve_cov(curve, d_start, d_end):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)
    return xf.visuals.rendering.render_df_color_range(
        df.cov(),
    )
```



```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
import functools
# @functools.lru_cache(maxsize=10)
def fit_pca_kernel(curve, d_start, d_end, n = 3):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)

    data = (df,)

    n_kernels = 1
    n_factors = n
    
    N_STAGES = 7

    model, STAGES = xf.Model().init_stages(N_STAGES)
    INPUTS, SETUP, PARAMS, SCALING, KERNELS, KERNEL_AGG, ENCODE, DECODE = STAGES

    model = (
        model.add_input(xf.nodes.inputs.dfs.Input_DataFrame_Wide(
            allow_missing_columns=True,
            allow_missing_indices=False,
            allow_new_columns=True,
            allow_new_indices=False,
            na_threshold_columns=0.,
            na_threshold_indices=0.,
        ))
        .add_input(xf.nodes.inputs.nds.Input_NDArray(
            numpy.linspace(0, 1, len(df.columns))
        ))
        .add_node(SETUP, xf.nodes.cov.vanilla.Cov(
            data=xf.Loc.result(INPUTS, 0),
        ), static = True)
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (n_kernels,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (n_kernels,) # c
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (n_kernels,) # sigma
        ))
        .add_node(SCALING, xf.nodes.scaling.scalar.Scale_Expit(
            data=xf.Loc.param(PARAMS, 1),
        ))
        # .add_node(PARAMS, xf.nodes.params.random.Gaussian(
        #     (n_factors,) # sigma
        # ))
        # .add_node(PARAMS, xf.nodes.params.random.Orthogonal(
        #     shape=(len(df.columns), n_factors,),
        # )) 
        .add_node(KERNELS, xf.nodes.cov.kernels.VKernel_Linear(
            a=xf.Loc.param(PARAMS, 0),
            c=xf.Loc.result(SCALING, 0),
            # c=xf.Loc.param(PARAMS, 1),
            sigma=xf.Loc.param(PARAMS, 2),
            data=xf.Loc.result(INPUTS, 1),
            sigma_sq=False,
        ))
        .add_node(KERNEL_AGG, xf.nodes.cov.kernels.Kernel_Sum(
            kernel=xf.Loc.result(KERNELS, 0)
        ))
        # .add_node(ENCODE, xf.nodes.pca.vanilla.PCA_Encoder(
        #     data=xf.Loc.result(INPUTS, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        #     n=n_factors,
        # ))
        # .add_node(DECODE, xf.nodes.pca.vanilla.PCA_Decoder(
        #     factors=xf.Loc.result(ENCODE, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_XD2Xt_Cov(
        #     X=xf.Loc.param(PARAMS, 3),
        #     D = xf.Loc.param(PARAMS, 2),
        #     cov=xf.Loc.result(KERNEL_AGG, 0),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_Orthonormal(
        #     data=xf.Loc.param(ENCODE, 0),
        #     T=True,
        # ))
        # .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
        #     l=xf.Loc.result(INPUTS, 0),
        #     r=xf.Loc.result(DECODE, 0),
        # ))
        .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
            l=xf.Loc.result(KERNEL_AGG, 0),
            r=xf.Loc.result(SETUP, 0),
        ))
        # factor variance max / mean zero / diag factor cov?
    )

    model = model.init(data).optimise(
        data,
        iters = 5000,
        rand_init=10, 
        max_error_unchanged=0.5,
    )
    results = model.apply(data)

    params = model.params[PARAMS]

    # assumes centering?

    cov = results[KERNEL_AGG][0]
    
    # weights = params[3]
    # sigma = params[2]
    a = params[0]
    c = results[SCALING][0]
    sigma=params[2]

    print(a)
    print(c)
    print(sigma)

    return df, cov
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def plot_kernel_cov(curve, d_start, d_end):
    df, cov = fit_pca_kernel(curve, d_start, d_end)
    return xf.visuals.rendering.render_df_color_range(
        pandas.DataFrame(
            cov,
            index=df.columns,
            columns=df.columns,
        ),
        # v_min=-1.,
        # v_max=.1,
    )
```




```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
import functools
# @functools.lru_cache(maxsize=10)
def fit_pca_kernel2(curve, d_start, d_end, n = 3):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)

    data = (df,)

    n_kernels = 3
    n_factors = n
    
    N_STAGES = 7

    model, STAGES = xf.Model().init_stages(N_STAGES)
    INPUTS, SETUP, PARAMS, SCALING, KERNELS, KERNEL_AGG, ENCODE, DECODE = STAGES

    model = (
        model.add_input(xf.nodes.inputs.dfs.Input_DataFrame_Wide(
            allow_missing_columns=True,
            allow_missing_indices=False,
            allow_new_columns=True,
            allow_new_indices=False,
            na_threshold_columns=0.,
            na_threshold_indices=0.,
        ))
        .add_input(xf.nodes.inputs.nds.Input_NDArray(
            numpy.linspace(0, 1, len(df.columns))
        ))
        .add_node(SETUP, xf.nodes.cov.vanilla.Cov(
            data=xf.Loc.result(INPUTS, 0),
        ), static = True)
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # c
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1, 2,) # c
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        # .add_node(PARAMS, xf.nodes.params.random.Gaussian(
        #     (n_factors,) # sigma
        # ))
        # .add_node(PARAMS, xf.nodes.params.random.Orthogonal(
        #     shape=(len(df.columns), n_factors,),
        # ))
        .add_node(SCALING, xf.nodes.scaling.scalar.Scale_Expit(
            data=xf.Loc.param(PARAMS, 1),
        ))
        .add_node(SCALING, xf.nodes.scaling.scalar.Scale_Expit(
            data=xf.Loc.param(PARAMS, 3),
        ))
        .add_node(KERNELS, xf.nodes.cov.kernels.VKernel_Linear(
            a=xf.Loc.param(PARAMS, 0),
            c=xf.Loc.result(SCALING, 0),
            sigma=xf.Loc.param(PARAMS, 4),
            data=xf.Loc.result(INPUTS, 1),
            sigma_sq=False,
        ))
        .add_node(KERNELS, xf.nodes.cov.kernels.VKernel_VLinear(
            a=xf.Loc.param(PARAMS, 2),
            c=xf.Loc.result(SCALING, 1),
            sigma=xf.Loc.param(PARAMS, 5),
            data=xf.Loc.result(INPUTS, 1),
            sigma_sq=False,
        ))
        .add_node(KERNEL_AGG, xf.nodes.cov.kernels.Kernel_Sum(
            kernels=xt.iTuple((
                xf.Loc.result(KERNELS, 0),
                xf.Loc.result(KERNELS, 1),
            ))
        ))
        # .add_node(ENCODE, xf.nodes.pca.vanilla.PCA_Encoder(
        #     data=xf.Loc.result(INPUTS, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        #     n=n_factors,
        # ))
        # .add_node(DECODE, xf.nodes.pca.vanilla.PCA_Decoder(
        #     factors=xf.Loc.result(ENCODE, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_XD2Xt_Cov(
        #     X=xf.Loc.param(PARAMS, 3),
        #     D = xf.Loc.param(PARAMS, 2),
        #     cov=xf.Loc.result(KERNEL_AGG, 0),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_Orthonormal(
        #     data=xf.Loc.param(ENCODE, 0),
        #     T=True,
        # ))
        # .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
        #     l=xf.Loc.result(INPUTS, 0),
        #     r=xf.Loc.result(DECODE, 0),
        # ))
        .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
            l=xf.Loc.result(KERNEL_AGG, 0),
            r=xf.Loc.result(SETUP, 0),
        ))
        # factor variance max / mean zero / diag factor cov?
    )

    model = model.init(data).optimise(
        data,
        iters = 5000,
        rand_init=10, 
        max_error_unchanged=0.5,
    )
    results = model.apply(data)

    params = model.params[PARAMS]

    # assumes centering?

    cov = results[KERNEL_AGG][0]
    
    # weights = params[3]
    # sigma = params[2]
    a = params[0]
    a2 = params[2]

    c = results[SCALING][0]
    c2 = results[SCALING][1]

    sigma=params[4]
    sigma2=params[5]

    print(a, a2)
    print(c, c2)
    print(sigma, sigma2)

    return df, cov
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def plot_kernel2_cov(curve, d_start, d_end):
    df, cov = fit_pca_kernel2(curve, d_start, d_end)
    return xf.visuals.rendering.render_df_color_range(
        pandas.DataFrame(
            cov,
            index=df.columns,
            columns=df.columns,
        ),
        # v_min=-1.,
        # v_max=.1,
    )
```



```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
import functools
# @functools.lru_cache(maxsize=10)
def fit_pca_kernel3(curve, d_start, d_end, n = 3):
    df = dfs_curves[curve]
    df = xf.utils.dfs.index_date_filter(df, date_start=d_start, date_end=d_end)

    data = (df,)

    n_kernels = 3
    n_factors = n
    
    N_STAGES = 7

    model, STAGES = xf.Model().init_stages(N_STAGES)
    INPUTS, SETUP, PARAMS, SCALING, KERNELS, KERNEL_AGG, ENCODE, DECODE = STAGES

    model = (
        model.add_input(xf.nodes.inputs.dfs.Input_DataFrame_Wide(
            allow_missing_columns=True,
            allow_missing_indices=False,
            allow_new_columns=True,
            allow_new_indices=False,
            na_threshold_columns=0.,
            na_threshold_indices=0.,
        ))
        .add_input(xf.nodes.inputs.nds.Input_NDArray(
            numpy.linspace(0, 1, len(df.columns))
        ))
        .add_node(SETUP, xf.nodes.cov.vanilla.Cov(
            data=xf.Loc.result(INPUTS, 0),
        ), static = True)
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # c
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # a
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1, 2,) # c
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # sigma
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # sigma
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # sigma (rbf)
        ))
        .add_node(PARAMS, xf.nodes.params.random.Gaussian(
            (1,) # l (rbf)
        ))
        # .add_node(PARAMS, xf.nodes.params.random.Gaussian(
        #     (n_factors,) # sigma
        # ))
        # .add_node(PARAMS, xf.nodes.params.random.Orthogonal(
        #     shape=(len(df.columns), n_factors,),
        # ))
        .add_node(SCALING, xf.nodes.scaling.scalar.Scale_Expit(
            data=xf.Loc.param(PARAMS, 1),
        ))
        .add_node(SCALING, xf.nodes.scaling.scalar.Scale_Expit(
            data=xf.Loc.param(PARAMS, 3),
        ))
        .add_node(KERNELS, xf.nodes.cov.kernels.VKernel_Linear(
            a=xf.Loc.param(PARAMS, 0),
            c=xf.Loc.result(SCALING, 0),
            sigma=xf.Loc.param(PARAMS, 4),
            data=xf.Loc.result(INPUTS, 1),
            sigma_sq=False,
        ))
        .add_node(KERNELS, xf.nodes.cov.kernels.VKernel_VLinear(
            a=xf.Loc.param(PARAMS, 2),
            c=xf.Loc.result(SCALING, 1),
            sigma=xf.Loc.param(PARAMS, 5),
            data=xf.Loc.result(INPUTS, 1),
            sigma_sq=False,
        ))
        .add_node(KERNELS, xf.nodes.cov.kernels.Kernel_RBF(
            sigma=xf.Loc.param(PARAMS, 6),
            l=xf.Loc.param(PARAMS, 7),
            data=xf.Loc.result(INPUTS, 1),
        ))
        .add_node(KERNEL_AGG, xf.nodes.cov.kernels.Kernel_Sum(
            kernels=xt.iTuple((
                xf.Loc.result(KERNELS, 0),
                xf.Loc.result(KERNELS, 1),
                xf.Loc.result(KERNELS, 2),
            ))
        ))
        # .add_node(ENCODE, xf.nodes.pca.vanilla.PCA_Encoder(
        #     data=xf.Loc.result(INPUTS, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        #     n=n_factors,
        # ))
        # .add_node(DECODE, xf.nodes.pca.vanilla.PCA_Decoder(
        #     factors=xf.Loc.result(ENCODE, 0),
        #     weights=xf.Loc.result(PARAMS, 3),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_XD2Xt_Cov(
        #     X=xf.Loc.param(PARAMS, 3),
        #     D = xf.Loc.param(PARAMS, 2),
        #     cov=xf.Loc.result(KERNEL_AGG, 0),
        # ))
        # .add_constraint(xf.nodes.constraints.linalg.Constraint_Orthonormal(
        #     data=xf.Loc.param(ENCODE, 0),
        #     T=True,
        # ))
        # .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
        #     l=xf.Loc.result(INPUTS, 0),
        #     r=xf.Loc.result(DECODE, 0),
        # ))
        .add_constraint(xf.nodes.constraints.loss.Constraint_MSE(
            l=xf.Loc.result(KERNEL_AGG, 0),
            r=xf.Loc.result(SETUP, 0),
        ))
        # factor variance max / mean zero / diag factor cov?
    )

    model = model.init(data).optimise(
        data,
        iters = 5000,
        rand_init=10, 
        max_error_unchanged=0.5,
    )
    results = model.apply(data)

    params = model.params[PARAMS]

    # assumes centering?

    cov = results[KERNEL_AGG][0]
    
    # weights = params[3]
    # sigma = params[2]
    a = params[0]
    a2 = params[2]

    c = results[SCALING][0]
    c2 = results[SCALING][1]

    sigma=params[4]
    sigma2=params[5]

    print(a, a2)
    print(c, c2)
    print(sigma, sigma2)

    return df, cov
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
def plot_kernel3_cov(curve, d_start, d_end):
    df, cov = fit_pca_kernel3(curve, d_start, d_end)
    return xf.visuals.rendering.render_df_color_range(
        pandas.DataFrame(
            cov,
            index=df.columns,
            columns=df.columns,
        ),
        # v_min=-1.,
        # v_max=.1,
    )
```
NOTE: unsure if the zip / map is screwing with the backprop, hence why all the c collapse?


```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
plot_kernel3_cov("USD-S", xf.utils.dates.y(2005), xf.utils.dates.y(2010))
```
```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
plot_kernel2_cov("USD-S", xf.utils.dates.y(2005), xf.utils.dates.y(2010))
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
plot_kernel_cov("USD-S", xf.utils.dates.y(2005), xf.utils.dates.y(2010))
```

```{python}
#| code-fold: true
#| code-summary: "Sector Weights Chart"
curve_cov("USD-S", xf.utils.dates.y(2005), xf.utils.dates.y(2010))
```


Maybe plot the diffs so we can see where going wrong

Essentially:

1: linear

2: linear + softmax(bi-linear)

3: linear + softmax(bi-linear) + rbf